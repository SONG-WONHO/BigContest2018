{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모든 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중요 피처 뽑는 함수\n",
    "- input: data_columns, feature_importances, num\n",
    "- output: list\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_feautre(columns, feature_importance, num):\n",
    "    \n",
    "    #딕셔너리\n",
    "    dic = {}\n",
    "    for value in [list(v) for v in zip(columns, feature_importance)]:\n",
    "        dic[value[1]] = value[0] \n",
    "        \n",
    "    sorted_list = sorted(dic)\n",
    "    sorted_list.reverse()\n",
    "    \n",
    "    i = 0\n",
    "    result = []\n",
    "    for y in sorted_list:\n",
    "        result.append(dic[y])\n",
    "        i = i+1\n",
    "        if(i == num):\n",
    "            break\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 로딩\n",
    "x_train_load_default = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_activity.csv').sort_values(by='acc_id', ascending=True)\n",
    "x_train_load_reversing = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_activity_new.csv').sort_values(by='acc_id', ascending=True)\n",
    "x_train_load_704 = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_activity_704.csv').sort_values(by='acc_id', ascending=True)\n",
    "x_train_load_main = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_data.csv').sort_values(by='acc_id', ascending=True)\n",
    "x_train_load_fin_v1 = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_activity_final_v1.csv').sort_values(by='acc_id', ascending=True)\n",
    "x_train_load_fin_v2 = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_activity_final_v2.csv').sort_values(by='acc_id', ascending=True)\n",
    "x_train_load_fin_v3 = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_activity_final_v3.csv').sort_values(by='acc_id', ascending=True)\n",
    "x_train_load_fin_v4 = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_activity_final_v4.csv').sort_values(by='acc_id', ascending=True)\n",
    "\n",
    "y_train_load = pd.read_csv('C://Users//zeus_//Desktop//champion_data//train/train_label.csv').sort_values(by='acc_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_default = x_train_load_default\n",
    "x_train_reversing = x_train_load_reversing\n",
    "x_train_704 = x_train_load_704\n",
    "x_train_main = x_train_load_main\n",
    "x_train_fin_v1 = x_train_load_fin_v1\n",
    "x_train_fin_v2 = x_train_load_fin_v2\n",
    "x_train_fin_v3 = x_train_load_fin_v3\n",
    "x_train_fin_v4 = x_train_load_fin_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_defailt와 x_train_reversing은 주차별 정리 x\n",
    "x_train_default = x_train_default.groupby('acc_id').mean()\n",
    "x_train_reversing = x_train_reversing.groupby('acc_id').mean()\n",
    "x_train_default = x_train_default.reset_index()\n",
    "x_train_reversing = x_train_reversing.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 3 & 4 Unnamed: 0\n",
    "x_train_default = x_train_default.drop(['acc_id'], axis=1)\n",
    "x_train_reversing = x_train_reversing.drop(['acc_id'], axis=1)\n",
    "x_train_704 = x_train_load_704.drop(['acc_id'], axis=1)\n",
    "x_train_main = x_train_load_main.drop(['acc_id'], axis=1)\n",
    "x_train_fin_v1 = x_train_load_fin_v1.drop(['acc_id'], axis=1)\n",
    "x_train_fin_v2 = x_train_load_fin_v2.drop(['acc_id'], axis=1)\n",
    "x_train_fin_v3 = x_train_load_fin_v3.drop(['acc_id', 'Unnamed: 0'], axis=1)\n",
    "x_train_fin_v4 = x_train_load_fin_v4.drop(['acc_id', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y_train_load.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ==> Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자율평가 : 0.7317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7059096811264727\n"
     ]
    }
   ],
   "source": [
    "scores_default = cross_val_score(forest, x_train_default, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7056768019934031\n"
     ]
    }
   ],
   "source": [
    "scores_reversing = cross_val_score(forest, x_train_reversing, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_reversing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359673413366196\n"
     ]
    }
   ],
   "source": [
    "scores_704 = cross_val_score(forest, x_train_704, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_704))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7372411135119707\n"
     ]
    }
   ],
   "source": [
    "scores_main = cross_val_score(forest, x_train_main, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7355285577237447\n"
     ]
    }
   ],
   "source": [
    "scores_fin_v1 = cross_val_score(forest, x_train_fin_v1, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_fin_v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737491952548978\n"
     ]
    }
   ],
   "source": [
    "scores_fin_v2 = cross_val_score(forest, x_train_fin_v2, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_fin_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7358411079961099\n"
     ]
    }
   ],
   "source": [
    "scores_fin_v3 = cross_val_score(forest, x_train_fin_v3, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_fin_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734810602098659\n"
     ]
    }
   ],
   "source": [
    "scores_fin_v4 = cross_val_score(forest, x_train_fin_v4, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_fin_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7353129510358583\n"
     ]
    }
   ],
   "source": [
    "scores_temp = cross_val_score(forest, train_temp, y_data, cv=5, scoring=\"f1_macro\")\n",
    "print(np.mean(scores_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 후보 1: x_train_fin_v2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_feature = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_feature.fit(x_train_fin_v2, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = select_important_feautre(x_train_fin_v2.columns, forest_feature.feature_importances_, 677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 개수 : 677 => f1 score: 0.7366008109043884\n",
      "feature 개수 : 676 => f1 score: 0.7363031166905191\n",
      "feature 개수 : 675 => f1 score: 0.7375353711808268\n",
      "feature 개수 : 674 => f1 score: 0.7378785225669741\n",
      "feature 개수 : 673 => f1 score: 0.7366006114281994\n",
      "feature 개수 : 672 => f1 score: 0.7368885120112788\n",
      "feature 개수 : 671 => f1 score: 0.7373897112574298\n",
      "feature 개수 : 670 => f1 score: 0.7371913462455206\n",
      "feature 개수 : 669 => f1 score: 0.736502811512128\n",
      "feature 개수 : 668 => f1 score: 0.7365086716128152\n",
      "feature 개수 : 667 => f1 score: 0.7371524898747214\n",
      "feature 개수 : 666 => f1 score: 0.7369153461633312\n",
      "feature 개수 : 665 => f1 score: 0.7374315739928817\n",
      "feature 개수 : 664 => f1 score: 0.7369102615128311\n",
      "feature 개수 : 663 => f1 score: 0.7369169973094593\n",
      "feature 개수 : 662 => f1 score: 0.7377624582198605\n",
      "feature 개수 : 661 => f1 score: 0.7374515213057633\n",
      "feature 개수 : 660 => f1 score: 0.7366727905474576\n",
      "feature 개수 : 659 => f1 score: 0.7364625329784644\n",
      "feature 개수 : 658 => f1 score: 0.7375718600520498\n",
      "feature 개수 : 657 => f1 score: 0.7374339600908785\n",
      "feature 개수 : 656 => f1 score: 0.7377611401775308\n",
      "feature 개수 : 655 => f1 score: 0.7375176715459529\n",
      "feature 개수 : 654 => f1 score: 0.7367034179489964\n",
      "feature 개수 : 653 => f1 score: 0.7372511782780817\n",
      "feature 개수 : 652 => f1 score: 0.737588570162675\n",
      "feature 개수 : 651 => f1 score: 0.7367855109334938\n",
      "feature 개수 : 650 => f1 score: 0.7370312455927589\n",
      "feature 개수 : 649 => f1 score: 0.7375325961475855\n",
      "feature 개수 : 648 => f1 score: 0.7368207510422395\n",
      "feature 개수 : 647 => f1 score: 0.7373623133107897\n",
      "feature 개수 : 646 => f1 score: 0.7368980621250456\n",
      "feature 개수 : 645 => f1 score: 0.7373725497595334\n",
      "feature 개수 : 644 => f1 score: 0.7371415244560253\n",
      "feature 개수 : 643 => f1 score: 0.737272940892142\n",
      "feature 개수 : 642 => f1 score: 0.7364506782371691\n",
      "feature 개수 : 641 => f1 score: 0.7360396483045355\n",
      "feature 개수 : 640 => f1 score: 0.7371327562191617\n",
      "feature 개수 : 639 => f1 score: 0.7367571355854772\n",
      "feature 개수 : 638 => f1 score: 0.7371947022822385\n",
      "feature 개수 : 637 => f1 score: 0.7362134420917011\n",
      "feature 개수 : 636 => f1 score: 0.7367811201245086\n",
      "feature 개수 : 635 => f1 score: 0.736423700438864\n",
      "feature 개수 : 634 => f1 score: 0.7368761369593833\n",
      "feature 개수 : 633 => f1 score: 0.736548544863129\n",
      "feature 개수 : 632 => f1 score: 0.7374018913382261\n",
      "feature 개수 : 631 => f1 score: 0.7375030990945688\n",
      "feature 개수 : 630 => f1 score: 0.7366598389004044\n",
      "feature 개수 : 629 => f1 score: 0.7373002693425967\n",
      "feature 개수 : 628 => f1 score: 0.7372616226848651\n",
      "feature 개수 : 627 => f1 score: 0.7362014205376227\n",
      "feature 개수 : 626 => f1 score: 0.7373839919621288\n",
      "feature 개수 : 625 => f1 score: 0.7365450980134663\n",
      "feature 개수 : 624 => f1 score: 0.7374907923147648\n",
      "feature 개수 : 623 => f1 score: 0.7370461726002491\n",
      "feature 개수 : 622 => f1 score: 0.7375264487107371\n",
      "feature 개수 : 621 => f1 score: 0.7372626290330404\n",
      "feature 개수 : 620 => f1 score: 0.7367044862548714\n",
      "feature 개수 : 619 => f1 score: 0.7372325785223159\n",
      "feature 개수 : 618 => f1 score: 0.7366432006867877\n",
      "feature 개수 : 617 => f1 score: 0.7363625786957757\n",
      "feature 개수 : 616 => f1 score: 0.7367231953066862\n",
      "feature 개수 : 615 => f1 score: 0.737199121279479\n",
      "feature 개수 : 614 => f1 score: 0.737893926136739\n",
      "feature 개수 : 613 => f1 score: 0.7367985672724549\n",
      "feature 개수 : 612 => f1 score: 0.736747007425566\n",
      "feature 개수 : 611 => f1 score: 0.7368624726696021\n",
      "feature 개수 : 610 => f1 score: 0.7370751370798005\n",
      "feature 개수 : 609 => f1 score: 0.7373417535569183\n",
      "feature 개수 : 608 => f1 score: 0.7364853813289074\n",
      "feature 개수 : 607 => f1 score: 0.7375661262319151\n",
      "feature 개수 : 606 => f1 score: 0.7366935154875405\n",
      "feature 개수 : 605 => f1 score: 0.7366020647902289\n",
      "feature 개수 : 604 => f1 score: 0.7367829085011192\n",
      "feature 개수 : 603 => f1 score: 0.73727038249971\n",
      "feature 개수 : 602 => f1 score: 0.7368998803641571\n",
      "feature 개수 : 601 => f1 score: 0.737328647453257\n",
      "feature 개수 : 600 => f1 score: 0.7373183363417197\n",
      "feature 개수 : 599 => f1 score: 0.737119740021686\n",
      "feature 개수 : 598 => f1 score: 0.7370924224780189\n",
      "feature 개수 : 597 => f1 score: 0.7370150584815661\n",
      "feature 개수 : 596 => f1 score: 0.7370385043796758\n",
      "feature 개수 : 595 => f1 score: 0.7365677413777094\n",
      "feature 개수 : 594 => f1 score: 0.7369713798776203\n",
      "feature 개수 : 593 => f1 score: 0.7362335900291859\n",
      "feature 개수 : 592 => f1 score: 0.7364815975397405\n",
      "feature 개수 : 591 => f1 score: 0.7373801069204412\n",
      "feature 개수 : 590 => f1 score: 0.7368012977330032\n",
      "feature 개수 : 589 => f1 score: 0.7372515060982158\n",
      "feature 개수 : 588 => f1 score: 0.7374611417189534\n",
      "feature 개수 : 587 => f1 score: 0.7363202914307394\n",
      "feature 개수 : 586 => f1 score: 0.7371528292756556\n",
      "feature 개수 : 585 => f1 score: 0.7366429596329038\n",
      "feature 개수 : 584 => f1 score: 0.7371860027286736\n",
      "feature 개수 : 583 => f1 score: 0.7373895083370767\n",
      "feature 개수 : 582 => f1 score: 0.7375157896769423\n",
      "feature 개수 : 581 => f1 score: 0.7371191020215928\n",
      "feature 개수 : 580 => f1 score: 0.7367130275913707\n",
      "feature 개수 : 579 => f1 score: 0.7361113447374651\n",
      "feature 개수 : 578 => f1 score: 0.737039585092212\n",
      "feature 개수 : 577 => f1 score: 0.736683037874886\n",
      "feature 개수 : 576 => f1 score: 0.736716223126334\n",
      "feature 개수 : 575 => f1 score: 0.7369592597169634\n",
      "feature 개수 : 574 => f1 score: 0.7374629511217224\n",
      "feature 개수 : 573 => f1 score: 0.7375373194192321\n",
      "feature 개수 : 572 => f1 score: 0.7373808206515573\n",
      "feature 개수 : 571 => f1 score: 0.7370409283687902\n",
      "feature 개수 : 570 => f1 score: 0.7365769567988353\n",
      "feature 개수 : 569 => f1 score: 0.7365474793993565\n",
      "feature 개수 : 568 => f1 score: 0.7369006958604211\n",
      "feature 개수 : 567 => f1 score: 0.7374192235260882\n",
      "feature 개수 : 566 => f1 score: 0.7364233083689534\n",
      "feature 개수 : 565 => f1 score: 0.7357984856269482\n",
      "feature 개수 : 564 => f1 score: 0.73728285949715\n",
      "feature 개수 : 563 => f1 score: 0.7376315583245938\n",
      "feature 개수 : 562 => f1 score: 0.7368548260451442\n",
      "feature 개수 : 561 => f1 score: 0.7369486364982007\n",
      "feature 개수 : 560 => f1 score: 0.7365782536668244\n",
      "feature 개수 : 559 => f1 score: 0.7379397752768045\n",
      "feature 개수 : 558 => f1 score: 0.7364848226821946\n",
      "feature 개수 : 557 => f1 score: 0.736204661839707\n",
      "feature 개수 : 556 => f1 score: 0.737026886766294\n",
      "feature 개수 : 555 => f1 score: 0.736215299655343\n",
      "feature 개수 : 554 => f1 score: 0.7368102577775674\n",
      "feature 개수 : 553 => f1 score: 0.7370019737894756\n",
      "feature 개수 : 552 => f1 score: 0.7366587412631248\n",
      "feature 개수 : 551 => f1 score: 0.7376704266656363\n",
      "feature 개수 : 550 => f1 score: 0.7376889491595396\n",
      "feature 개수 : 549 => f1 score: 0.7367827547196004\n",
      "feature 개수 : 548 => f1 score: 0.7372473708228708\n",
      "feature 개수 : 547 => f1 score: 0.7365446423835459\n",
      "feature 개수 : 546 => f1 score: 0.7371195846627903\n",
      "feature 개수 : 545 => f1 score: 0.7374142599396214\n",
      "feature 개수 : 544 => f1 score: 0.7370439059746918\n",
      "feature 개수 : 543 => f1 score: 0.7369250594310037\n",
      "feature 개수 : 542 => f1 score: 0.7360463375406254\n",
      "feature 개수 : 541 => f1 score: 0.7368657390523217\n",
      "feature 개수 : 540 => f1 score: 0.7380218001211233\n",
      "feature 개수 : 539 => f1 score: 0.7369982336967617\n",
      "feature 개수 : 538 => f1 score: 0.737481732182803\n",
      "feature 개수 : 537 => f1 score: 0.7374347598918052\n",
      "feature 개수 : 536 => f1 score: 0.7361083711405632\n",
      "feature 개수 : 535 => f1 score: 0.7364440639146247\n",
      "feature 개수 : 534 => f1 score: 0.737241463179279\n",
      "feature 개수 : 533 => f1 score: 0.7375178958150161\n",
      "feature 개수 : 532 => f1 score: 0.7376775933442319\n",
      "feature 개수 : 531 => f1 score: 0.7364562890235582\n",
      "feature 개수 : 530 => f1 score: 0.7369212225057454\n",
      "feature 개수 : 529 => f1 score: 0.7361841407656784\n",
      "feature 개수 : 528 => f1 score: 0.7366373495527739\n",
      "feature 개수 : 527 => f1 score: 0.7372819701982918\n",
      "feature 개수 : 526 => f1 score: 0.7365950908385941\n",
      "feature 개수 : 525 => f1 score: 0.7370781732103595\n",
      "feature 개수 : 524 => f1 score: 0.7369153150896952\n",
      "feature 개수 : 523 => f1 score: 0.7373071039012358\n",
      "feature 개수 : 522 => f1 score: 0.7367447426324102\n",
      "feature 개수 : 521 => f1 score: 0.737387800201871\n",
      "feature 개수 : 520 => f1 score: 0.7368174908193124\n",
      "feature 개수 : 519 => f1 score: 0.736641868039091\n",
      "feature 개수 : 518 => f1 score: 0.7359682055428418\n",
      "feature 개수 : 517 => f1 score: 0.7361623991982469\n",
      "feature 개수 : 516 => f1 score: 0.7365850742067592\n",
      "feature 개수 : 515 => f1 score: 0.7362939297556592\n",
      "feature 개수 : 514 => f1 score: 0.737017772850059\n",
      "feature 개수 : 513 => f1 score: 0.7363726812641487\n",
      "feature 개수 : 512 => f1 score: 0.7375116901644532\n",
      "feature 개수 : 511 => f1 score: 0.737105026869158\n",
      "feature 개수 : 510 => f1 score: 0.7360930952958327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 개수 : 509 => f1 score: 0.7371989350401825\n",
      "feature 개수 : 508 => f1 score: 0.737175583428954\n",
      "feature 개수 : 507 => f1 score: 0.7355622827747592\n",
      "feature 개수 : 506 => f1 score: 0.7364830541578695\n",
      "feature 개수 : 505 => f1 score: 0.7371522237060646\n",
      "feature 개수 : 504 => f1 score: 0.7371635965593173\n",
      "feature 개수 : 503 => f1 score: 0.7369825257867502\n",
      "feature 개수 : 502 => f1 score: 0.7358499829019378\n",
      "feature 개수 : 501 => f1 score: 0.736519852399484\n",
      "feature 개수 : 500 => f1 score: 0.7365515000840024\n",
      "feature 개수 : 499 => f1 score: 0.7374072050876094\n",
      "feature 개수 : 498 => f1 score: 0.73620123350762\n",
      "feature 개수 : 497 => f1 score: 0.7371329992392279\n",
      "feature 개수 : 496 => f1 score: 0.7370718403469001\n",
      "feature 개수 : 495 => f1 score: 0.7366842936081589\n",
      "feature 개수 : 494 => f1 score: 0.7370781230231984\n",
      "feature 개수 : 493 => f1 score: 0.7362383335708199\n",
      "feature 개수 : 492 => f1 score: 0.7366975031387216\n",
      "feature 개수 : 491 => f1 score: 0.7370723844633675\n",
      "feature 개수 : 490 => f1 score: 0.7366663025410414\n",
      "feature 개수 : 489 => f1 score: 0.7368053416697589\n",
      "feature 개수 : 488 => f1 score: 0.7359507824261715\n",
      "feature 개수 : 487 => f1 score: 0.7369442579062156\n",
      "feature 개수 : 486 => f1 score: 0.7362868509938444\n",
      "feature 개수 : 485 => f1 score: 0.7363609969221838\n",
      "feature 개수 : 484 => f1 score: 0.7360647902929327\n",
      "feature 개수 : 483 => f1 score: 0.7378144115868872\n",
      "feature 개수 : 482 => f1 score: 0.7365307239332992\n",
      "feature 개수 : 481 => f1 score: 0.7361996207700378\n",
      "feature 개수 : 480 => f1 score: 0.7362137316348735\n",
      "feature 개수 : 479 => f1 score: 0.7369995915451535\n",
      "feature 개수 : 478 => f1 score: 0.7357521242444999\n",
      "feature 개수 : 477 => f1 score: 0.7365528996424677\n",
      "feature 개수 : 476 => f1 score: 0.7367549345508342\n",
      "feature 개수 : 475 => f1 score: 0.7361761711922374\n",
      "feature 개수 : 474 => f1 score: 0.7363951938482263\n",
      "feature 개수 : 473 => f1 score: 0.7372889769018247\n",
      "feature 개수 : 472 => f1 score: 0.7365666785624644\n",
      "feature 개수 : 471 => f1 score: 0.7360539047323111\n",
      "feature 개수 : 470 => f1 score: 0.7371085835033784\n",
      "feature 개수 : 469 => f1 score: 0.7363683564991178\n",
      "feature 개수 : 468 => f1 score: 0.7367483101558562\n",
      "feature 개수 : 467 => f1 score: 0.7369838858720474\n",
      "feature 개수 : 466 => f1 score: 0.7356555580957639\n",
      "feature 개수 : 465 => f1 score: 0.7370256934108257\n",
      "feature 개수 : 464 => f1 score: 0.7367235480001523\n",
      "feature 개수 : 463 => f1 score: 0.7371655390266432\n",
      "feature 개수 : 462 => f1 score: 0.7364699986049128\n",
      "feature 개수 : 461 => f1 score: 0.7363884975660728\n",
      "feature 개수 : 460 => f1 score: 0.7370451668962861\n",
      "feature 개수 : 459 => f1 score: 0.7363173093179197\n",
      "feature 개수 : 458 => f1 score: 0.7362870228027842\n",
      "feature 개수 : 457 => f1 score: 0.7365067072549797\n",
      "feature 개수 : 456 => f1 score: 0.7372245989313553\n",
      "feature 개수 : 455 => f1 score: 0.7372949509695553\n",
      "feature 개수 : 454 => f1 score: 0.7367226892665514\n",
      "feature 개수 : 453 => f1 score: 0.7361214044136902\n",
      "feature 개수 : 452 => f1 score: 0.7370207361811103\n",
      "feature 개수 : 451 => f1 score: 0.736054323193752\n",
      "feature 개수 : 450 => f1 score: 0.7372906298376547\n",
      "feature 개수 : 449 => f1 score: 0.7365600552777367\n",
      "feature 개수 : 448 => f1 score: 0.736101058534975\n",
      "feature 개수 : 447 => f1 score: 0.7375353747112874\n",
      "feature 개수 : 446 => f1 score: 0.7367572475867381\n",
      "feature 개수 : 445 => f1 score: 0.7363524855053588\n",
      "feature 개수 : 444 => f1 score: 0.7360771425531543\n",
      "feature 개수 : 443 => f1 score: 0.7365548118867881\n",
      "feature 개수 : 442 => f1 score: 0.7361951871660957\n",
      "feature 개수 : 441 => f1 score: 0.7357682046494111\n",
      "feature 개수 : 440 => f1 score: 0.7371583446572814\n",
      "feature 개수 : 439 => f1 score: 0.7363364545397888\n",
      "feature 개수 : 438 => f1 score: 0.7358016444757094\n",
      "feature 개수 : 437 => f1 score: 0.7366938841061985\n",
      "feature 개수 : 436 => f1 score: 0.7366183128088903\n",
      "feature 개수 : 435 => f1 score: 0.7367912378334495\n",
      "feature 개수 : 434 => f1 score: 0.737236192048457\n",
      "feature 개수 : 433 => f1 score: 0.736781852418836\n",
      "feature 개수 : 432 => f1 score: 0.7367146027143179\n",
      "feature 개수 : 431 => f1 score: 0.7361776539440459\n",
      "feature 개수 : 430 => f1 score: 0.7367122011308912\n",
      "feature 개수 : 429 => f1 score: 0.7363730752469978\n",
      "feature 개수 : 428 => f1 score: 0.7369377500142983\n",
      "feature 개수 : 427 => f1 score: 0.7367019214474457\n",
      "feature 개수 : 426 => f1 score: 0.7370548297853243\n",
      "feature 개수 : 425 => f1 score: 0.7364035127637665\n",
      "feature 개수 : 424 => f1 score: 0.7364226817577914\n",
      "feature 개수 : 423 => f1 score: 0.7359980801961311\n",
      "feature 개수 : 422 => f1 score: 0.7369170532656268\n",
      "feature 개수 : 421 => f1 score: 0.7361049229492856\n",
      "feature 개수 : 420 => f1 score: 0.7366076684958929\n",
      "feature 개수 : 419 => f1 score: 0.7364035235343589\n",
      "feature 개수 : 418 => f1 score: 0.7364204267592441\n",
      "feature 개수 : 417 => f1 score: 0.7353667625297948\n",
      "feature 개수 : 416 => f1 score: 0.7363112661777622\n",
      "feature 개수 : 415 => f1 score: 0.7362127171470464\n",
      "feature 개수 : 414 => f1 score: 0.7365742112087361\n",
      "feature 개수 : 413 => f1 score: 0.7366380197153273\n",
      "feature 개수 : 412 => f1 score: 0.736657958273414\n",
      "feature 개수 : 411 => f1 score: 0.7367609403719472\n",
      "feature 개수 : 410 => f1 score: 0.7373089939147194\n",
      "feature 개수 : 409 => f1 score: 0.7372641174571484\n",
      "feature 개수 : 408 => f1 score: 0.7365728026189481\n",
      "feature 개수 : 407 => f1 score: 0.7364858256613688\n",
      "feature 개수 : 406 => f1 score: 0.7358242749120782\n",
      "feature 개수 : 405 => f1 score: 0.7367334083416578\n",
      "feature 개수 : 404 => f1 score: 0.7363439531645671\n",
      "feature 개수 : 403 => f1 score: 0.7359513125831336\n",
      "feature 개수 : 402 => f1 score: 0.7366691302245314\n",
      "feature 개수 : 401 => f1 score: 0.7360322320834765\n",
      "feature 개수 : 400 => f1 score: 0.7364395602438988\n",
      "feature 개수 : 399 => f1 score: 0.736655082026035\n",
      "feature 개수 : 398 => f1 score: 0.7367782720144088\n",
      "feature 개수 : 397 => f1 score: 0.7357880753309242\n",
      "feature 개수 : 396 => f1 score: 0.7363359085730374\n",
      "feature 개수 : 395 => f1 score: 0.7362721697936104\n",
      "feature 개수 : 394 => f1 score: 0.7367566747062881\n",
      "feature 개수 : 393 => f1 score: 0.7360205545382068\n",
      "feature 개수 : 392 => f1 score: 0.7355572071673635\n",
      "feature 개수 : 391 => f1 score: 0.7369674700314719\n",
      "feature 개수 : 390 => f1 score: 0.7365249663296086\n",
      "feature 개수 : 389 => f1 score: 0.7367294438580967\n",
      "feature 개수 : 388 => f1 score: 0.7368730885543828\n",
      "feature 개수 : 387 => f1 score: 0.7368379870712353\n",
      "feature 개수 : 386 => f1 score: 0.7354346690728321\n",
      "feature 개수 : 385 => f1 score: 0.7367808488859691\n",
      "feature 개수 : 384 => f1 score: 0.7362581884134985\n",
      "feature 개수 : 383 => f1 score: 0.7364681266647551\n",
      "feature 개수 : 382 => f1 score: 0.7370483809189275\n",
      "feature 개수 : 381 => f1 score: 0.736797332961467\n",
      "feature 개수 : 380 => f1 score: 0.7361734522160244\n",
      "feature 개수 : 379 => f1 score: 0.7362804608800586\n",
      "feature 개수 : 378 => f1 score: 0.7366676972305705\n",
      "feature 개수 : 377 => f1 score: 0.7363549528083214\n",
      "feature 개수 : 376 => f1 score: 0.7365510556931334\n",
      "feature 개수 : 375 => f1 score: 0.7365640895455187\n",
      "feature 개수 : 374 => f1 score: 0.7358557222443575\n",
      "feature 개수 : 373 => f1 score: 0.736144847597675\n",
      "feature 개수 : 372 => f1 score: 0.7354680636946036\n",
      "feature 개수 : 371 => f1 score: 0.7360794174259059\n",
      "feature 개수 : 370 => f1 score: 0.7359250491426881\n",
      "feature 개수 : 369 => f1 score: 0.7360499204312438\n",
      "feature 개수 : 368 => f1 score: 0.7365821806823469\n",
      "feature 개수 : 367 => f1 score: 0.7367754688277127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-1f5d90ed803a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mx_train_fin_v2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train_fin_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mscores_fin_v2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_fin_v2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f1_macro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"feature 개수 : {} => f1 score: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m677\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_fin_v2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 316\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0m_set_random_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[1;34m(estimator, random_state)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mto_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'random_state'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__random_state'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mto_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_RAND_SEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[1;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;31m# catch deprecated param values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# to represent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\inspect.py\u001b[0m in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   3031\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m     \u001b[1;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3033\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[1;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   2781\u001b[0m         \u001b[1;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2782\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[1;32m-> 2783\u001b[1;33m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[0;32m   2784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2785\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2256\u001b[0m         \u001b[1;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2257\u001b[0m         \u001b[1;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2258\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func)\u001b[0m\n\u001b[0;32m   2133\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2134\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[1;32m-> 2135\u001b[1;33m                                     \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2136\u001b[0m                                     default=defaults[offset]))\n\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,677):\n",
    "    \n",
    "    x_train_fin_v2 = x_train_fin_v2.loc[:, feature_list]\n",
    "    \n",
    "    scores_fin_v2 = cross_val_score(forest, x_train_fin_v2, y_data, cv=5, scoring=\"f1_macro\")\n",
    "    print(\"feature 개수 : {} => f1 score: {}\".format(677-i, np.mean(scores_fin_v2)))\n",
    "    \n",
    "    feature_list = feature_list[0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 674 => 0.7378\n",
    "- 662 => 0.7377\n",
    "- 665 => 0.7377\n",
    "- 614 => 0.7378\n",
    "- 559 => 0.7379\n",
    "- 540 => 0.7380\n",
    "- 483 => 0.7378"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(num):\n",
    "    x_train , x_val, x_test, y_train, y_val, y_test = (\"\",\"\",\"\",\"\",\"\",\"\")\n",
    "    if num == 1:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_default, y_data, test_size=0.2, random_state=200)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)        \n",
    "    elif num == 2:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_reversing, y_data, test_size=0.2, random_state=200)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)        \n",
    "    elif num == 3:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_704, y_data, test_size=0.2, random_state=200)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)        \n",
    "    elif num == 4:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_main, y_data, test_size=0.2, random_state=200)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)        \n",
    "    elif num == 5:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_fin_v1, y_data, test_size=0.2, random_state=200)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)        \n",
    "    elif num == 6:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_fin_v2, y_data, test_size=0.2, random_state=200)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)        \n",
    "    elif num == 7:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_fin_v3, y_data, test_size=0.2, random_state=200)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)\n",
    "    else:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_fin_v4, y_data, test_size=0.2, random_state=200)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)\n",
    "    return (x_train, x_val, x_test, y_train, y_val, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = split_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.77      0.91      0.83     19985\n",
      "      month       0.90      0.77      0.83     20072\n",
      "   retained       0.97      0.92      0.94     19959\n",
      "       week       0.98      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.90      0.90      0.90     80000\n",
      "\n",
      "0.8976008227205373\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.60      0.65      0.62      2508\n",
      "      month       0.66      0.50      0.57      2470\n",
      "   retained       0.74      0.82      0.78      2539\n",
      "       week       0.84      0.88      0.86      2483\n",
      "\n",
      "avg / total       0.71      0.71      0.71     10000\n",
      "\n",
      "0.7071788675196555\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.62      0.67      0.64      2507\n",
      "      month       0.68      0.51      0.58      2458\n",
      "   retained       0.74      0.82      0.78      2502\n",
      "       week       0.85      0.89      0.87      2533\n",
      "\n",
      "avg / total       0.72      0.72      0.72     10000\n",
      "\n",
      "0.7182601287684569\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=-1, max_depth=24)\n",
    "\n",
    "forest.fit(x_train,y_train)\n",
    "\n",
    "print(\"\\n======================훈련셋======================\\n\")\n",
    "print(classification_report(y_train, forest.predict(x_train)))\n",
    "print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "print(\"\\n======================검증셋======================\\\\n\")\n",
    "print(classification_report(y_val, forest.predict(x_val)))\n",
    "print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "print(\"\\n======================테스트셋=====================\\n\")\n",
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train_reversing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = split_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.70      0.86      0.78     19985\n",
      "      month       0.87      0.69      0.77     20072\n",
      "   retained       0.93      0.88      0.91     19959\n",
      "       week       0.95      0.99      0.97     19984\n",
      "\n",
      "avg / total       0.86      0.85      0.85     80000\n",
      "\n",
      "0.8543989631160648\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.59      0.67      0.63      2508\n",
      "      month       0.67      0.47      0.55      2470\n",
      "   retained       0.75      0.81      0.78      2539\n",
      "       week       0.83      0.88      0.86      2483\n",
      "\n",
      "avg / total       0.71      0.71      0.70     10000\n",
      "\n",
      "0.7036576548706781\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.61      0.68      0.65      2507\n",
      "      month       0.70      0.50      0.58      2458\n",
      "   retained       0.74      0.82      0.78      2502\n",
      "       week       0.84      0.89      0.87      2533\n",
      "\n",
      "avg / total       0.72      0.72      0.72     10000\n",
      "\n",
      "0.7174611870728965\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=-1, max_depth=20)\n",
    "\n",
    "forest.fit(x_train,y_train)\n",
    "\n",
    "print(\"\\n======================훈련셋======================\\n\")\n",
    "print(classification_report(y_train, forest.predict(x_train)))\n",
    "print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "print(\"\\n======================검증셋======================\\\\n\")\n",
    "print(classification_report(y_val, forest.predict(x_val)))\n",
    "print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "print(\"\\n======================테스트셋=====================\\n\")\n",
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train_704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = split_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.85      0.88      0.86     19985\n",
      "      month       0.88      0.85      0.86     20072\n",
      "   retained       0.99      0.95      0.97     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.92      0.92      0.92     80000\n",
      "\n",
      "0.9192662670051905\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.65      0.64      2508\n",
      "      month       0.67      0.55      0.60      2470\n",
      "   retained       0.77      0.84      0.81      2539\n",
      "       week       0.83      0.90      0.86      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.729126381773454\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.64      0.65      2507\n",
      "      month       0.67      0.56      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.84      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7359782734516997\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=-1, max_depth=28)\n",
    "\n",
    "forest.fit(x_train,y_train)\n",
    "\n",
    "print(\"\\n======================훈련셋======================\\n\")\n",
    "print(classification_report(y_train, forest.predict(x_train)))\n",
    "print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "print(\"\\n======================검증셋======================\\\\n\")\n",
    "print(classification_report(y_val, forest.predict(x_val)))\n",
    "print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "print(\"\\n======================테스트셋=====================\\n\")\n",
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = split_data(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.86      0.88      0.87     19985\n",
      "      month       0.88      0.87      0.87     20072\n",
      "   retained       0.99      0.95      0.97     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.93      0.92      0.92     80000\n",
      "\n",
      "0.9247763788659633\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.65      0.65      2508\n",
      "      month       0.67      0.56      0.61      2470\n",
      "   retained       0.77      0.83      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7316165470154045\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.65      0.65      2507\n",
      "      month       0.68      0.57      0.62      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7391817937802192\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=-1, max_depth=29)\n",
    "\n",
    "forest.fit(x_train,y_train)\n",
    "\n",
    "print(\"\\n======================훈련셋======================\\n\")\n",
    "print(classification_report(y_train, forest.predict(x_train)))\n",
    "print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "print(\"\\n======================검증셋======================\\\\n\")\n",
    "print(classification_report(y_val, forest.predict(x_val)))\n",
    "print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "print(\"\\n======================테스트셋=====================\\n\")\n",
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train_fin_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = split_data(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.83      0.89      0.86     19985\n",
      "      month       0.88      0.83      0.86     20072\n",
      "   retained       0.99      0.94      0.96     19959\n",
      "       week       0.96      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.91      0.91      0.91     80000\n",
      "\n",
      "0.9136323686706131\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.66      0.65      2508\n",
      "      month       0.68      0.54      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.83      0.89      0.86      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7278792024593553\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.65      0.65      2507\n",
      "      month       0.69      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7364796235302993\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=-1, max_depth=28)\n",
    "\n",
    "forest.fit(x_train,y_train)\n",
    "\n",
    "print(\"\\n======================훈련셋======================\\n\")\n",
    "print(classification_report(y_train, forest.predict(x_train)))\n",
    "print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "print(\"\\n======================검증셋======================\\\\n\")\n",
    "print(classification_report(y_val, forest.predict(x_val)))\n",
    "print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "print(\"\\n======================테스트셋=====================\\n\")\n",
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train_fin_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = split_data(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.86      0.90      0.88     19985\n",
      "      month       0.89      0.86      0.88     20072\n",
      "   retained       0.99      0.95      0.97     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.93      0.93      0.93     80000\n",
      "\n",
      "0.927495928343022\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.66      0.65      2508\n",
      "      month       0.67      0.55      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7296756460370032\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.65      0.65      2507\n",
      "      month       0.68      0.56      0.62      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7387984036414306\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=-1, max_depth=28)\n",
    "\n",
    "forest.fit(x_train,y_train)\n",
    "\n",
    "print(\"\\n======================훈련셋======================\\n\")\n",
    "print(classification_report(y_train, forest.predict(x_train)))\n",
    "print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "print(\"\\n======================검증셋======================\\\\n\")\n",
    "print(classification_report(y_val, forest.predict(x_val)))\n",
    "print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "print(\"\\n======================테스트셋=====================\\n\")\n",
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train_fin_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = split_data(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.91      0.93      0.92     19985\n",
      "      month       0.92      0.91      0.92     20072\n",
      "   retained       0.99      0.97      0.98     19959\n",
      "       week       0.98      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.95      0.95      0.95     80000\n",
      "\n",
      "0.9503482185202455\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.65      0.65      2508\n",
      "      month       0.66      0.56      0.61      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7311680850922961\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.65      0.65      2507\n",
      "      month       0.68      0.57      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.75      0.74     10000\n",
      "\n",
      "0.7393762882188624\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=-1, max_depth=28)\n",
    "\n",
    "forest.fit(x_train,y_train)\n",
    "\n",
    "print(\"\\n======================훈련셋======================\\n\")\n",
    "print(classification_report(y_train, forest.predict(x_train)))\n",
    "print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "print(\"\\n======================검증셋======================\\\\n\")\n",
    "print(classification_report(y_val, forest.predict(x_val)))\n",
    "print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "print(\"\\n======================테스트셋=====================\\n\")\n",
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train_fin_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = split_data(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.89      0.92      0.91     19985\n",
      "      month       0.92      0.90      0.91     20072\n",
      "   retained       0.99      0.96      0.98     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.94      0.94      0.94     80000\n",
      "\n",
      "0.9441106249961742\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.65      0.64      2508\n",
      "      month       0.67      0.55      0.61      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7292575363066067\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.65      0.65      2507\n",
      "      month       0.68      0.56      0.62      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7388151187045702\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=-1, max_depth=26)\n",
    "\n",
    "forest.fit(x_train,y_train)\n",
    "\n",
    "print(\"\\n======================훈련셋======================\\n\")\n",
    "print(classification_report(y_train, forest.predict(x_train)))\n",
    "print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "print(\"\\n======================검증셋======================\\\\n\")\n",
    "print(classification_report(y_val, forest.predict(x_val)))\n",
    "print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "print(\"\\n======================테스트셋=====================\\n\")\n",
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = pd.concat([x_train_default,x_train_reversing,x_train_704,x_train_main,x_train_fin_v1,x_train_fin_v2,x_train_fin_v3,x_train_fin_v4], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train_temp, y_data, test_size=0.2, random_state=200)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max feature => 685, max depth => 44\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9670942405784086\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.86      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7351610469489168\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.61      0.62      2508\n",
      "      month       0.63      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.86      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7220745213517697\n",
      "max feature => 532, max depth => 21\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.85      0.90      0.87     19985\n",
      "      month       0.91      0.84      0.87     20072\n",
      "   retained       0.96      0.95      0.96     19959\n",
      "       week       0.96      0.99      0.97     19984\n",
      "\n",
      "avg / total       0.92      0.92      0.92     80000\n",
      "\n",
      "0.9189766322987419\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.67      0.66      2507\n",
      "      month       0.69      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.80      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7368250263032905\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.66      0.65      2508\n",
      "      month       0.67      0.53      0.59      2470\n",
      "   retained       0.77      0.84      0.81      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7283469742942917\n",
      "max feature => 321, max depth => 34\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.96      0.96      0.96     80000\n",
      "\n",
      "0.9646918878871629\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.67      0.63      0.65      2507\n",
      "      month       0.67      0.59      0.62      2458\n",
      "   retained       0.76      0.86      0.81      2502\n",
      "       week       0.86      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7394810302807535\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7231638248404757\n",
      "max feature => 599, max depth => 19\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.80      0.88      0.84     19985\n",
      "      month       0.89      0.79      0.83     20072\n",
      "   retained       0.95      0.93      0.94     19959\n",
      "       week       0.95      0.99      0.97     19984\n",
      "\n",
      "avg / total       0.90      0.90      0.90     80000\n",
      "\n",
      "0.8952582259360389\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.67      0.66      2507\n",
      "      month       0.69      0.53      0.60      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.92      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7378013443192192\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.68      0.65      2508\n",
      "      month       0.68      0.52      0.59      2470\n",
      "   retained       0.78      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7296299168108099\n",
      "max feature => 427, max depth => 10\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.61      0.70      0.66     19985\n",
      "      month       0.73      0.49      0.59     20072\n",
      "   retained       0.78      0.84      0.81     19959\n",
      "       week       0.83      0.93      0.88     19984\n",
      "\n",
      "avg / total       0.74      0.74      0.73     80000\n",
      "\n",
      "0.7329152862722029\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.61      0.68      0.64      2507\n",
      "      month       0.70      0.47      0.56      2458\n",
      "   retained       0.76      0.82      0.79      2502\n",
      "       week       0.81      0.91      0.86      2533\n",
      "\n",
      "avg / total       0.72      0.72      0.71     10000\n",
      "\n",
      "0.7127772184807638\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.60      0.68      0.64      2508\n",
      "      month       0.68      0.45      0.54      2470\n",
      "   retained       0.76      0.82      0.79      2539\n",
      "       week       0.80      0.89      0.84      2483\n",
      "\n",
      "avg / total       0.71      0.71      0.70     10000\n",
      "\n",
      "0.70306151615311\n",
      "max feature => 207, max depth => 22\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.87      0.90      0.89     19985\n",
      "      month       0.91      0.87      0.89     20072\n",
      "   retained       0.97      0.96      0.96     19959\n",
      "       week       0.96      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.93      0.93      0.93     80000\n",
      "\n",
      "0.9296477484142481\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.66      0.66      2507\n",
      "      month       0.68      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7388471685046393\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.66      0.65      2508\n",
      "      month       0.67      0.54      0.60      2470\n",
      "   retained       0.77      0.84      0.81      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7309093806356299\n",
      "max feature => 206, max depth => 34\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9652379603804419\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7356080665491925\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.61      0.62      2508\n",
      "      month       0.64      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7224937029666963\n",
      "max feature => 218, max depth => 45\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.95     19985\n",
      "      month       0.93      0.96      0.94     20072\n",
      "   retained       1.00      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9681748700130914\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.67      0.62      0.64      2507\n",
      "      month       0.66      0.59      0.62      2458\n",
      "   retained       0.75      0.86      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7351945214699367\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.61      0.62      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7226023372589235\n",
      "max feature => 581, max depth => 13\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.67      0.77      0.71     19985\n",
      "      month       0.78      0.59      0.68     20072\n",
      "   retained       0.86      0.87      0.87     19959\n",
      "       week       0.88      0.96      0.92     19984\n",
      "\n",
      "avg / total       0.80      0.80      0.79     80000\n",
      "\n",
      "0.7943541479160737\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.68      0.66      2507\n",
      "      month       0.70      0.51      0.59      2458\n",
      "   retained       0.77      0.83      0.80      2502\n",
      "       week       0.83      0.92      0.87      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.729592196372578\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.62      0.68      0.65      2508\n",
      "      month       0.69      0.49      0.57      2470\n",
      "   retained       0.77      0.83      0.80      2539\n",
      "       week       0.81      0.90      0.85      2483\n",
      "\n",
      "avg / total       0.72      0.72      0.72     10000\n",
      "\n",
      "0.7170447839206868\n",
      "max feature => 387, max depth => 22\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.87      0.90      0.89     19985\n",
      "      month       0.92      0.86      0.89     20072\n",
      "   retained       0.97      0.96      0.96     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.93      0.93      0.93     80000\n",
      "\n",
      "0.9284663352365042\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.66      0.65      2507\n",
      "      month       0.68      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7375447157013091\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.66      0.65      2508\n",
      "      month       0.67      0.54      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.86      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7277350289992586\n",
      "max feature => 47, max depth => 18\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.73      0.83      0.78     19985\n",
      "      month       0.83      0.69      0.75     20072\n",
      "   retained       0.94      0.90      0.92     19959\n",
      "       week       0.92      0.98      0.95     19984\n",
      "\n",
      "avg / total       0.85      0.85      0.85     80000\n",
      "\n",
      "0.8503143193678382\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.68      0.66      2507\n",
      "      month       0.71      0.53      0.60      2458\n",
      "   retained       0.77      0.84      0.80      2502\n",
      "       week       0.84      0.92      0.87      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7347484615136397\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.68      0.65      2508\n",
      "      month       0.69      0.50      0.58      2470\n",
      "   retained       0.77      0.83      0.80      2539\n",
      "       week       0.82      0.90      0.86      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.72     10000\n",
      "\n",
      "0.7244341941602706\n",
      "max feature => 170, max depth => 21\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.84      0.90      0.87     19985\n",
      "      month       0.90      0.83      0.86     20072\n",
      "   retained       0.97      0.95      0.96     19959\n",
      "       week       0.96      0.99      0.97     19984\n",
      "\n",
      "avg / total       0.92      0.91      0.91     80000\n",
      "\n",
      "0.9146934885266743\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.67      0.66      2507\n",
      "      month       0.70      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.75      0.74     10000\n",
      "\n",
      "0.7410270718937076\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.67      0.65      2508\n",
      "      month       0.68      0.53      0.60      2470\n",
      "   retained       0.77      0.84      0.81      2539\n",
      "       week       0.84      0.90      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7296045200097434\n",
      "max feature => 332, max depth => 21\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.85      0.89      0.87     19985\n",
      "      month       0.91      0.84      0.87     20072\n",
      "   retained       0.96      0.95      0.96     19959\n",
      "       week       0.96      0.99      0.97     19984\n",
      "\n",
      "avg / total       0.92      0.92      0.92     80000\n",
      "\n",
      "0.9185628717689425\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.67      0.66      2507\n",
      "      month       0.69      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.92      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.75      0.74     10000\n",
      "\n",
      "0.7404568774983878\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.66      0.65      2508\n",
      "      month       0.67      0.54      0.60      2470\n",
      "   retained       0.77      0.84      0.81      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7294911825485906\n",
      "max feature => 317, max depth => 15\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.71      0.80      0.75     19985\n",
      "      month       0.82      0.66      0.73     20072\n",
      "   retained       0.90      0.89      0.90     19959\n",
      "       week       0.91      0.97      0.94     19984\n",
      "\n",
      "avg / total       0.83      0.83      0.83     80000\n",
      "\n",
      "0.8306602101269023\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.68      0.66      2507\n",
      "      month       0.70      0.53      0.60      2458\n",
      "   retained       0.77      0.84      0.80      2502\n",
      "       week       0.84      0.92      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7351603335103293\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.62      0.68      0.65      2508\n",
      "      month       0.69      0.50      0.58      2470\n",
      "   retained       0.78      0.83      0.80      2539\n",
      "       week       0.82      0.90      0.86      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.72     10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7237835706265888\n",
      "max feature => 406, max depth => 18\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.78      0.86      0.82     19985\n",
      "      month       0.87      0.76      0.81     20072\n",
      "   retained       0.95      0.92      0.93     19959\n",
      "       week       0.94      0.98      0.96     19984\n",
      "\n",
      "avg / total       0.88      0.88      0.88     80000\n",
      "\n",
      "0.8806008168406925\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.68      0.66      2507\n",
      "      month       0.70      0.54      0.61      2458\n",
      "   retained       0.77      0.84      0.81      2502\n",
      "       week       0.85      0.92      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7382518067252491\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.68      0.65      2508\n",
      "      month       0.68      0.52      0.59      2470\n",
      "   retained       0.78      0.84      0.81      2539\n",
      "       week       0.84      0.90      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7294805166765063\n",
      "max feature => 128, max depth => 48\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.95     19985\n",
      "      month       0.93      0.96      0.94     20072\n",
      "   retained       1.00      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9688372348154296\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.67      0.62      0.64      2507\n",
      "      month       0.67      0.59      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7380396884425605\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.86      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7225333492819465\n",
      "max feature => 230, max depth => 27\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.93      0.92      0.93     19985\n",
      "      month       0.93      0.93      0.93     20072\n",
      "   retained       0.98      0.98      0.98     19959\n",
      "       week       0.98      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.96      0.96      0.96     80000\n",
      "\n",
      "0.9558846058388827\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.63      0.65      2507\n",
      "      month       0.67      0.57      0.62      2458\n",
      "   retained       0.75      0.85      0.80      2502\n",
      "       week       0.86      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7361695273044788\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.63      0.63      2508\n",
      "      month       0.65      0.56      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7268169823650042\n",
      "max feature => 240, max depth => 41\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.96      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9674680722811255\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.67      0.63      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7362964415144264\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.62      0.63      2508\n",
      "      month       0.64      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7216842257309126\n",
      "max feature => 400, max depth => 46\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9676454788158528\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.73618106888086\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.61      0.62      2508\n",
      "      month       0.63      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7218682569181119\n",
      "max feature => 77, max depth => 47\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.95     19985\n",
      "      month       0.93      0.96      0.94     20072\n",
      "   retained       1.00      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9689536502170744\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.75      0.86      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7352835322835409\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.61      0.62      2508\n",
      "      month       0.64      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.86      2483\n",
      "\n",
      "avg / total       0.72      0.72      0.72     10000\n",
      "\n",
      "0.7203568359464568\n",
      "max feature => 85, max depth => 23\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.86      0.90      0.88     19985\n",
      "      month       0.91      0.86      0.88     20072\n",
      "   retained       0.98      0.96      0.97     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.93      0.93      0.93     80000\n",
      "\n",
      "0.9261840723646266\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.66      0.66      2507\n",
      "      month       0.69      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7381768453230522\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.67      0.65      2508\n",
      "      month       0.68      0.54      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7313410411090095\n",
      "max feature => 103, max depth => 10\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.61      0.69      0.65     19985\n",
      "      month       0.72      0.47      0.57     20072\n",
      "   retained       0.78      0.83      0.81     19959\n",
      "       week       0.81      0.93      0.86     19984\n",
      "\n",
      "avg / total       0.73      0.73      0.72     80000\n",
      "\n",
      "0.7232662907535578\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.61      0.68      0.64      2507\n",
      "      month       0.70      0.45      0.55      2458\n",
      "   retained       0.76      0.82      0.79      2502\n",
      "       week       0.80      0.91      0.85      2533\n",
      "\n",
      "avg / total       0.72      0.72      0.71     10000\n",
      "\n",
      "0.7088213355916149\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.60      0.68      0.64      2508\n",
      "      month       0.69      0.45      0.54      2470\n",
      "   retained       0.76      0.82      0.79      2539\n",
      "       week       0.79      0.89      0.84      2483\n",
      "\n",
      "avg / total       0.71      0.71      0.70     10000\n",
      "\n",
      "0.700480248393387\n",
      "max feature => 385, max depth => 25\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.92      0.92      0.92     19985\n",
      "      month       0.93      0.91      0.92     20072\n",
      "   retained       0.97      0.97      0.97     19959\n",
      "       week       0.98      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.95      0.95      0.95     80000\n",
      "\n",
      "0.9483491442526385\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.64      0.65      2507\n",
      "      month       0.68      0.57      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7371354130975832\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.64      0.64      2508\n",
      "      month       0.66      0.55      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7278248990992071\n",
      "max feature => 304, max depth => 48\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.95     19985\n",
      "      month       0.93      0.96      0.94     20072\n",
      "   retained       1.00      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9682851340992045\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.75      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7330138345847116\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.73     10000\n",
      "\n",
      "0.7248176979321987\n",
      "max feature => 96, max depth => 32\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.98      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.96      0.96      0.96     80000\n",
      "\n",
      "0.9643812837317459\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7332714492056867\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7245045162708802\n",
      "max feature => 622, max depth => 37\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9654364866408416\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7350318468541264\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.61      0.62      2508\n",
      "      month       0.64      0.57      0.61      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7233002300352165\n",
      "max feature => 433, max depth => 44\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9674169943650515\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7354612837752287\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.86      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7230134634994847\n",
      "max feature => 208, max depth => 29\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.94      0.94     20072\n",
      "   retained       0.98      0.98      0.98     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.96      0.96      0.96     80000\n",
      "\n",
      "0.9610305591522744\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.63      0.64      2507\n",
      "      month       0.67      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7361953925939229\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.62      0.63      2508\n",
      "      month       0.65      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.73     10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252621887923224\n",
      "max feature => 409, max depth => 29\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.94      0.93      0.93     19985\n",
      "      month       0.93      0.94      0.93     20072\n",
      "   retained       0.98      0.98      0.98     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.96      0.96      0.96     80000\n",
      "\n",
      "0.9597038867226055\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.63      0.64      2507\n",
      "      month       0.66      0.57      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7356448879516508\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.62      0.63      2508\n",
      "      month       0.65      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7242646410921421\n",
      "max feature => 158, max depth => 43\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.95     19985\n",
      "      month       0.93      0.96      0.94     20072\n",
      "   retained       1.00      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9681106294964152\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.67      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7350099839945513\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.61      0.62      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7213288688236189\n",
      "max feature => 481, max depth => 16\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.73      0.83      0.78     19985\n",
      "      month       0.84      0.70      0.76     20072\n",
      "   retained       0.92      0.90      0.91     19959\n",
      "       week       0.92      0.98      0.95     19984\n",
      "\n",
      "avg / total       0.85      0.85      0.85     80000\n",
      "\n",
      "0.8511993436854074\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.68      0.66      2507\n",
      "      month       0.70      0.53      0.60      2458\n",
      "   retained       0.77      0.84      0.81      2502\n",
      "       week       0.84      0.92      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7369478507585487\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.69      0.65      2508\n",
      "      month       0.69      0.52      0.59      2470\n",
      "   retained       0.78      0.83      0.81      2539\n",
      "       week       0.83      0.90      0.86      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7289562103602929\n",
      "max feature => 238, max depth => 38\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9668038794004181\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7343731289114221\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.65      0.57      0.61      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.73     10000\n",
      "\n",
      "0.7255575785091996\n",
      "max feature => 527, max depth => 43\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9670551392455086\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.67      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.86      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7349477656506412\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.64      0.56      0.60      2470\n",
      "   retained       0.76      0.85      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7228173233668465\n",
      "max feature => 619, max depth => 12\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.75      0.69     19985\n",
      "      month       0.77      0.56      0.65     20072\n",
      "   retained       0.83      0.86      0.85     19959\n",
      "       week       0.87      0.95      0.91     19984\n",
      "\n",
      "avg / total       0.78      0.78      0.77     80000\n",
      "\n",
      "0.7741351161410837\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.62      0.68      0.65      2507\n",
      "      month       0.70      0.49      0.58      2458\n",
      "   retained       0.77      0.83      0.80      2502\n",
      "       week       0.83      0.91      0.87      2533\n",
      "\n",
      "avg / total       0.73      0.73      0.72     10000\n",
      "\n",
      "0.7234386902087065\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.61      0.68      0.65      2508\n",
      "      month       0.69      0.47      0.56      2470\n",
      "   retained       0.77      0.83      0.80      2539\n",
      "       week       0.81      0.90      0.85      2483\n",
      "\n",
      "avg / total       0.72      0.72      0.71     10000\n",
      "\n",
      "0.7127330234594197\n",
      "max feature => 559, max depth => 45\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.96      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9674673121326632\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7329315077872925\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.61      0.62      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.86      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7231153336991517\n",
      "max feature => 64, max depth => 13\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.75      0.70     19985\n",
      "      month       0.76      0.56      0.65     20072\n",
      "   retained       0.85      0.86      0.85     19959\n",
      "       week       0.86      0.96      0.91     19984\n",
      "\n",
      "avg / total       0.78      0.78      0.78     80000\n",
      "\n",
      "0.7754061586775356\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.68      0.65      2507\n",
      "      month       0.70      0.49      0.58      2458\n",
      "   retained       0.77      0.84      0.80      2502\n",
      "       week       0.82      0.92      0.87      2533\n",
      "\n",
      "avg / total       0.73      0.73      0.72     10000\n",
      "\n",
      "0.7235605814502389\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.62      0.68      0.64      2508\n",
      "      month       0.69      0.47      0.56      2470\n",
      "   retained       0.76      0.83      0.79      2539\n",
      "       week       0.81      0.90      0.85      2483\n",
      "\n",
      "avg / total       0.72      0.72      0.71     10000\n",
      "\n",
      "0.7128003617036277\n",
      "max feature => 414, max depth => 21\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.85      0.90      0.87     19985\n",
      "      month       0.91      0.84      0.87     20072\n",
      "   retained       0.96      0.95      0.96     19959\n",
      "       week       0.96      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.92      0.92      0.92     80000\n",
      "\n",
      "0.9195951805881674\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.67      0.66      2507\n",
      "      month       0.69      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.75      0.74     10000\n",
      "\n",
      "0.7390384566998185\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.67      0.65      2508\n",
      "      month       0.67      0.53      0.59      2470\n",
      "   retained       0.77      0.84      0.81      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7275016518722429\n",
      "max feature => 246, max depth => 31\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.98      0.98      0.98     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.96      0.96      0.96     80000\n",
      "\n",
      "0.9629296543427717\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.63      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7349720870038032\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.64      0.56      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.86      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7231510726626041\n",
      "max feature => 127, max depth => 35\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9664263485663732\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7359275963898841\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.61      0.62      2508\n",
      "      month       0.64      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.721249593430404\n",
      "max feature => 591, max depth => 26\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.92      0.92      0.92     19985\n",
      "      month       0.93      0.92      0.92     20072\n",
      "   retained       0.98      0.98      0.98     19959\n",
      "       week       0.98      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.95      0.95      0.95     80000\n",
      "\n",
      "0.9515530055353367\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.63      0.65      2507\n",
      "      month       0.67      0.57      0.61      2458\n",
      "   retained       0.76      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7363099458227322\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.64      0.64      2508\n",
      "      month       0.65      0.56      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.86      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7260219302822143\n",
      "max feature => 43, max depth => 38\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.95     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       1.00      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9680142295542815\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.86      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7350449518162039\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.62      0.62      2508\n",
      "      month       0.64      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.86      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7210807227928656\n",
      "max feature => 121, max depth => 39\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.94      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       1.00      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9679699683711211\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.63      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7353578970789711\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7239441604380156\n",
      "max feature => 157, max depth => 14\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.69      0.78      0.73     19985\n",
      "      month       0.80      0.61      0.69     20072\n",
      "   retained       0.88      0.88      0.88     19959\n",
      "       week       0.89      0.97      0.92     19984\n",
      "\n",
      "avg / total       0.81      0.81      0.81     80000\n",
      "\n",
      "0.8071606421892945\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.68      0.66      2507\n",
      "      month       0.70      0.51      0.59      2458\n",
      "   retained       0.77      0.84      0.80      2502\n",
      "       week       0.83      0.92      0.87      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7306573681334486\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.62      0.68      0.65      2508\n",
      "      month       0.68      0.48      0.56      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.81      0.90      0.85      2483\n",
      "\n",
      "avg / total       0.72      0.72      0.72     10000\n",
      "\n",
      "0.7168225104578622\n",
      "max feature => 225, max depth => 38\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9666135205897606\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7350421721315761\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.73     10000\n",
      "\n",
      "0.7247052612936443\n",
      "max feature => 372, max depth => 24\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.90      0.91      0.91     19985\n",
      "      month       0.92      0.90      0.91     20072\n",
      "   retained       0.97      0.97      0.97     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.94      0.94      0.94     80000\n",
      "\n",
      "0.9428801397839653\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.65      0.65      2507\n",
      "      month       0.68      0.56      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.738809044289424\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.65      0.64      2508\n",
      "      month       0.66      0.56      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7302321406261216\n",
      "max feature => 693, max depth => 22\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.86      0.91      0.88     19985\n",
      "      month       0.91      0.86      0.89     20072\n",
      "   retained       0.97      0.96      0.96     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.93      0.93      0.93     80000\n",
      "\n",
      "0.9275265088783959\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.67      0.66      2507\n",
      "      month       0.69      0.55      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.75      0.74     10000\n",
      "\n",
      "0.7406128054386341\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.66      0.65      2508\n",
      "      month       0.67      0.54      0.60      2470\n",
      "   retained       0.77      0.83      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7273977376640339\n",
      "max feature => 399, max depth => 31\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.98      0.98      0.98     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.96      0.96      0.96     80000\n",
      "\n",
      "0.9621690931086258\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.61      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7328835075469701\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.65      0.57      0.61      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.73     10000\n",
      "\n",
      "0.7251507717122186\n",
      "max feature => 336, max depth => 41\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.96      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       1.00      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.97      0.97     80000\n",
      "\n",
      "0.9669187242459863\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7348649137335055\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.86      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.72     10000\n",
      "\n",
      "0.7234839913329889\n",
      "max feature => 463, max depth => 24\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.90      0.92      0.91     19985\n",
      "      month       0.92      0.90      0.91     20072\n",
      "   retained       0.97      0.97      0.97     19959\n",
      "       week       0.97      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.94      0.94      0.94     80000\n",
      "\n",
      "0.9430496500013595\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.64      0.65      2507\n",
      "      month       0.67      0.56      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.85      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7369053635566126\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.65      0.64      2508\n",
      "      month       0.66      0.55      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7288123587973753\n",
      "max feature => 217, max depth => 16\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.73      0.82      0.78     19985\n",
      "      month       0.84      0.69      0.76     20072\n",
      "   retained       0.92      0.90      0.91     19959\n",
      "       week       0.92      0.98      0.95     19984\n",
      "\n",
      "avg / total       0.85      0.85      0.85     80000\n",
      "\n",
      "0.8477648512192171\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.68      0.66      2507\n",
      "      month       0.70      0.53      0.60      2458\n",
      "   retained       0.78      0.84      0.81      2502\n",
      "       week       0.84      0.92      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.7367252703362055\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.68      0.65      2508\n",
      "      month       0.68      0.51      0.58      2470\n",
      "   retained       0.78      0.83      0.80      2539\n",
      "       week       0.83      0.90      0.86      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7248005382206713\n",
      "max feature => 230, max depth => 34\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.99      0.99      0.99     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.97      0.96      0.96     80000\n",
      "\n",
      "0.9649557736856538\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.86      0.90      0.88      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.7340851046896888\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.61      0.62      2508\n",
      "      month       0.64      0.56      0.60      2470\n",
      "   retained       0.76      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.72      0.72     10000\n",
      "\n",
      "0.7196165252358053\n",
      "max feature => 472, max depth => 19\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.80      0.87      0.84     19985\n",
      "      month       0.89      0.79      0.84     20072\n",
      "   retained       0.95      0.93      0.94     19959\n",
      "       week       0.95      0.99      0.97     19984\n",
      "\n",
      "avg / total       0.90      0.90      0.90     80000\n",
      "\n",
      "0.8961975314796655\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.68      0.66      2507\n",
      "      month       0.70      0.54      0.61      2458\n",
      "   retained       0.78      0.85      0.81      2502\n",
      "       week       0.85      0.92      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.75      0.74     10000\n",
      "\n",
      "0.7415965740188646\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.63      0.68      0.65      2508\n",
      "      month       0.68      0.52      0.59      2470\n",
      "   retained       0.78      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7280328794613422\n",
      "max feature => 430, max depth => 32\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.95      0.93      0.94     19985\n",
      "      month       0.93      0.95      0.94     20072\n",
      "   retained       0.98      0.98      0.98     19959\n",
      "       week       0.99      0.99      0.99     19984\n",
      "\n",
      "avg / total       0.96      0.96      0.96     80000\n",
      "\n",
      "0.9633673938020312\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.66      0.62      0.64      2507\n",
      "      month       0.66      0.58      0.62      2458\n",
      "   retained       0.76      0.85      0.80      2502\n",
      "       week       0.85      0.90      0.87      2533\n",
      "\n",
      "avg / total       0.73      0.74      0.74     10000\n",
      "\n",
      "0.7342079923087919\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.62      0.63      2508\n",
      "      month       0.64      0.57      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.85      0.88      0.87      2483\n",
      "\n",
      "avg / total       0.72      0.73      0.73     10000\n",
      "\n",
      "0.7251834189741478\n",
      "max feature => 26, max depth => 25\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.82      0.89      0.86     19985\n",
      "      month       0.89      0.82      0.85     20072\n",
      "   retained       0.99      0.94      0.96     19959\n",
      "       week       0.96      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.91      0.91      0.91     80000\n",
      "\n",
      "0.9122066989185376\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.67      0.66      2507\n",
      "      month       0.69      0.54      0.61      2458\n",
      "   retained       0.77      0.85      0.81      2502\n",
      "       week       0.84      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "0.736647307608879\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.67      0.65      2508\n",
      "      month       0.68      0.53      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.84      0.90      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.74      0.73     10000\n",
      "\n",
      "0.730014469946799\n",
      "max feature => 567, max depth => 24\n",
      "\n",
      "======================훈련셋======================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.90      0.91      0.91     19985\n",
      "      month       0.92      0.90      0.91     20072\n",
      "   retained       0.97      0.97      0.97     19959\n",
      "       week       0.98      0.99      0.98     19984\n",
      "\n",
      "avg / total       0.94      0.94      0.94     80000\n",
      "\n",
      "0.9427315364726562\n",
      "\n",
      "======================검증셋======================\\n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.65      0.65      0.65      2507\n",
      "      month       0.68      0.56      0.61      2458\n",
      "   retained       0.76      0.85      0.81      2502\n",
      "       week       0.86      0.91      0.88      2533\n",
      "\n",
      "avg / total       0.74      0.75      0.74     10000\n",
      "\n",
      "0.739385481811641\n",
      "\n",
      "======================테스트셋=====================\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     2month       0.64      0.65      0.64      2508\n",
      "      month       0.66      0.55      0.60      2470\n",
      "   retained       0.77      0.84      0.80      2539\n",
      "       week       0.84      0.89      0.87      2483\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n",
      "0.7285333897028817\n",
      "max feature => 420, max depth => 26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-65668eacc4ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n======================훈련셋======================\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\data_science\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(1,100000):\n",
    "    max_feature = random.sample(range(1,700),1)[0]\n",
    "    max_depth = random.sample(range(10,50), 1)[0]\n",
    "    \n",
    "    print(\"max feature => {}, max depth => {}\".format(max_feature, max_depth))\n",
    "    \n",
    "    forest = RandomForestClassifier(n_estimators=100, random_state=25, n_jobs=3, max_depth=max_depth, max_features=max_feature)\n",
    "\n",
    "    forest.fit(x_train,y_train)\n",
    "\n",
    "    print(\"\\n======================훈련셋======================\\n\")\n",
    "    print(classification_report(y_train, forest.predict(x_train)))\n",
    "    print(np.mean(f1_score(y_train, forest.predict(x_train), average=None)))\n",
    "\n",
    "    print(\"\\n======================검증셋======================\\\\n\")\n",
    "    print(classification_report(y_val, forest.predict(x_val)))\n",
    "    print(np.mean(f1_score(y_val, forest.predict(x_val), average=None)))\n",
    "\n",
    "    print(\"\\n======================테스트셋=====================\\n\")\n",
    "    print(classification_report(y_test, forest.predict(x_test)))\n",
    "    print(np.mean(f1_score(y_test, forest.predict(x_test), average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_load_default' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e4a4e2671da5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mx_train_load_default\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mx_train_load_reversing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mx_train_load_704\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mx_train_load_main\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mx_train_load_fin_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_load_default' is not defined"
     ]
    }
   ],
   "source": [
    "#메모리초기화\n",
    "del x_train_load_default\n",
    "del x_train_load_reversing \n",
    "del x_train_load_704\n",
    "del x_train_load_main\n",
    "del x_train_load_fin_v1\n",
    "del x_train_load_fin_v2 \n",
    "del x_train_load_fin_v3 \n",
    "del x_train_load_fin_v4 \n",
    "del x_train_default\n",
    "del x_train_reversing\n",
    "del x_train_704\n",
    "del x_train_main\n",
    "del x_train_fin_v1\n",
    "del x_train_fin_v2\n",
    "del x_train_fin_v3 \n",
    "del x_train_fin_v4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
