{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝 데이터 로드\n",
    "x_data = pd.read_csv('C:\\\\Users\\\\zeus_\\\\Desktop\\\\champion_data\\\\train\\\\train_activity.csv').sort_values(by='acc_id', ascending=True)\n",
    "y_data = pd.read_csv('C:\\\\Users\\\\zeus_\\\\Desktop\\\\champion_data\\\\train\\\\train_label.csv').sort_values(by='acc_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 440323 entries, 427043 to 315904\n",
      "Data columns (total 38 columns):\n",
      "wk                          440323 non-null int64\n",
      "acc_id                      440323 non-null object\n",
      "cnt_dt                      440323 non-null int64\n",
      "play_time                   440323 non-null float64\n",
      "npc_exp                     440323 non-null float64\n",
      "npc_hongmun                 440323 non-null float64\n",
      "quest_exp                   440323 non-null float64\n",
      "quest_hongmun               440323 non-null float64\n",
      "item_hongmun                440323 non-null float64\n",
      "game_combat_time            440323 non-null float64\n",
      "get_money                   440323 non-null float64\n",
      "duel_cnt                    440323 non-null float64\n",
      "duel_win                    440323 non-null float64\n",
      "partybattle_cnt             440323 non-null float64\n",
      "partybattle_win             440323 non-null float64\n",
      "cnt_enter_inzone_solo       440323 non-null float64\n",
      "cnt_enter_inzone_light      440323 non-null float64\n",
      "cnt_enter_inzone_skilled    440323 non-null float64\n",
      "cnt_enter_inzone_normal     440323 non-null float64\n",
      "cnt_enter_raid              440323 non-null float64\n",
      "cnt_enter_raid_light        440323 non-null float64\n",
      "cnt_enter_bam               440323 non-null float64\n",
      "cnt_clear_inzone_solo       440323 non-null float64\n",
      "cnt_clear_inzone_light      440323 non-null float64\n",
      "cnt_clear_inzone_skilled    440323 non-null float64\n",
      "cnt_clear_inzone_normal     440323 non-null float64\n",
      "cnt_clear_raid              440323 non-null float64\n",
      "cnt_clear_raid_light        440323 non-null float64\n",
      "cnt_clear_bam               440323 non-null float64\n",
      "normal_chat                 440323 non-null float64\n",
      "whisper_chat                440323 non-null float64\n",
      "district_chat               440323 non-null float64\n",
      "party_chat                  440323 non-null float64\n",
      "guild_chat                  440323 non-null float64\n",
      "faction_chat                440323 non-null float64\n",
      "cnt_use_buffitem            440323 non-null float64\n",
      "gathering_cnt               440323 non-null float64\n",
      "making_cnt                  440323 non-null float64\n",
      "dtypes: float64(35), int64(2), object(1)\n",
      "memory usage: 131.0+ MB\n"
     ]
    }
   ],
   "source": [
    "x_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data[x_data['wk'] == 8].values[:,2:]\n",
    "y_data = y_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.concatenate((x_data, x_data**2, x_data**3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = (x_data - x_data.min(axis=0)) / (x_data.max(axis=0) - x_data.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 108)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레이닝셋, 발리데이션셋 구분\n",
    "x_train = x_data[0:int(0.7 * len(x_data)), 2:] \n",
    "y_train = y_data[0:int(0.7 * len(x_data))]\n",
    "\n",
    "x_cv = x_data[int(0.7 * len(x_data)):, 2:] \n",
    "y_cv = y_data[int(0.7 * len(x_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=-1, max_features=10, max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.788\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트 정확도: {:.3f}\".format(forest.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크로스발리데이션 세트 정확도: 0.691\n"
     ]
    }
   ],
   "source": [
    "print(\"크로스발리데이션 세트 정확도: {:.3f}\".format(forest.score(x_cv, y_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한국어로 된 레이블을 숫자로 인코딩\n",
    "idx2label = list(set(y_train))\n",
    "label2idx = {c:i for i,c in enumerate(idx2label)}\n",
    "\n",
    "#new y_train & y_cv\n",
    "y_train = [label2idx[v] for v in y_train]\n",
    "y_cv = [label2idx[v] for v in y_cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 개수\n",
    "num_feature = len(x_train[0])\n",
    "learning_rate = 0.01\n",
    "training_epoch = 100\n",
    "batch_size = 100\n",
    "label = len(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, num_feature])\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_one_hot\n",
    "Y_one_hot = tf.one_hot(Y, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Layer1\n",
    "with tf.name_scope('layer1') as scope:\n",
    "    w1 = tf.get_variable(\"weight1\", [num_feature, 64], tf.float32, layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([64]), name = \"bias1\")\n",
    "    \n",
    "    layer1 = tf.nn.relu(tf.matmul(X,w1) + b1)\n",
    "    layer1 = tf.nn.dropout(layer1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer2\n",
    "with tf.name_scope('layer2') as scope:\n",
    "    w2 = tf.get_variable(\"weight2\", [64, 32], tf.float32, layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([32]), name = \"bias2\")\n",
    "    \n",
    "    layer2 = tf.nn.relu(tf.matmul(layer1,w2) + b2)\n",
    "    layer2 = tf.nn.dropout(layer2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer3\n",
    "with tf.name_scope('layer3') as scope:\n",
    "    w3 = tf.get_variable(\"weight3\", [32, 16], tf.float32, layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([16]), name = \"bias3\")\n",
    "    \n",
    "    layer3 = tf.nn.relu(tf.matmul(layer2,w3) + b3)\n",
    "    layer3 = tf.nn.dropout(layer3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer4\n",
    "with tf.name_scope('layer4') as scope:\n",
    "    w4 = tf.get_variable(\"weight4\", [16, 8], tf.float32, layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([8]), name = \"bias4\")\n",
    "    \n",
    "    layer4 = tf.nn.relu(tf.matmul(layer3,w4) + b4)\n",
    "    layer4 = tf.nn.dropout(layer4, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypothesis\n",
    "with tf.name_scope('hypothesis') as scope:\n",
    "    w5 = tf.get_variable(\"weight5\", [8, label], tf.float32, layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([label]), name = \"bias5\")\n",
    "    \n",
    "    logits = tf.matmul(layer4, w5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost Function - softmax cross entropy\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y_one_hot)\n",
    "    cost = tf.reduce_mean(cost)\n",
    "    tf.summary.scalar(\"cost\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train - Gradient Descent\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "prediction = tf.argmax(logits, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "with tf.name_scope(\"accuracy\") as scope:\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, tf.argmax(Y_one_hot,-1)), tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0]  cost 1.4154248598643706\n",
      "[epoch : 1]  cost 1.3894473896707802\n",
      "[epoch : 2]  cost 1.3867077159881571\n",
      "[epoch : 3]  cost 1.3859517688410636\n",
      "[epoch : 4]  cost 1.385778485706875\n",
      "[epoch : 5]  cost 1.3855467840603428\n",
      "[epoch : 6]  cost 1.384480219738823\n",
      "[epoch : 7]  cost 1.3833102124077936\n",
      "[epoch : 8]  cost 1.3774863507066466\n",
      "[epoch : 9]  cost 1.361754185812814\n",
      "[epoch : 10]  cost 1.3466261913095223\n",
      "[epoch : 11]  cost 1.3310263659272883\n",
      "[epoch : 12]  cost 1.3091901436873847\n",
      "[epoch : 13]  cost 1.2839823440143034\n",
      "[epoch : 14]  cost 1.2644122374057758\n",
      "[epoch : 15]  cost 1.250306055375508\n",
      "[epoch : 16]  cost 1.2360928225517271\n",
      "[epoch : 17]  cost 1.2213616372857774\n",
      "[epoch : 18]  cost 1.2046490081718984\n",
      "[epoch : 19]  cost 1.1910372920547212\n",
      "[epoch : 20]  cost 1.175767372846603\n",
      "[epoch : 21]  cost 1.167258646403039\n",
      "[epoch : 22]  cost 1.1586048700128282\n",
      "[epoch : 23]  cost 1.1543113952023634\n",
      "[epoch : 24]  cost 1.1480720460414913\n",
      "[epoch : 25]  cost 1.1461317828723372\n",
      "[epoch : 26]  cost 1.1437288322619032\n",
      "[epoch : 27]  cost 1.1443895108359194\n",
      "[epoch : 28]  cost 1.1397654239620494\n",
      "[epoch : 29]  cost 1.1384656723908027\n",
      "[epoch : 30]  cost 1.1364135851178851\n",
      "[epoch : 31]  cost 1.1323736302341738\n",
      "[epoch : 32]  cost 1.131023701259068\n",
      "[epoch : 33]  cost 1.1284092914206636\n",
      "[epoch : 34]  cost 1.1245191058090753\n",
      "[epoch : 35]  cost 1.1263311558961855\n",
      "[epoch : 36]  cost 1.1236767841236934\n",
      "[epoch : 37]  cost 1.1235268310138156\n",
      "[epoch : 38]  cost 1.1222152930498124\n",
      "[epoch : 39]  cost 1.1219349296603893\n",
      "[epoch : 40]  cost 1.1220855217320573\n",
      "[epoch : 41]  cost 1.1203902414866844\n",
      "[epoch : 42]  cost 1.1202973062651482\n",
      "[epoch : 43]  cost 1.120294656157494\n",
      "[epoch : 44]  cost 1.1160853281191414\n",
      "[epoch : 45]  cost 1.1160797671760831\n",
      "[epoch : 46]  cost 1.118378588557243\n",
      "[epoch : 47]  cost 1.113701692138399\n",
      "[epoch : 48]  cost 1.115214607375007\n",
      "[epoch : 49]  cost 1.1119012553351257\n",
      "[epoch : 50]  cost 1.1082247982706328\n",
      "[epoch : 51]  cost 1.098840612598829\n",
      "[epoch : 52]  cost 1.0933278365646089\n",
      "[epoch : 53]  cost 1.0908158402783532\n",
      "[epoch : 54]  cost 1.086926132440567\n",
      "[epoch : 55]  cost 1.083051344667163\n",
      "[epoch : 56]  cost 1.0820179025615961\n",
      "[epoch : 57]  cost 1.077984720809119\n",
      "[epoch : 58]  cost 1.0722173795529775\n",
      "[epoch : 59]  cost 1.0717559979643132\n",
      "[epoch : 60]  cost 1.0723741420677726\n",
      "[epoch : 61]  cost 1.0700022345781328\n",
      "[epoch : 62]  cost 1.0706170368194579\n",
      "[epoch : 63]  cost 1.0683838775328225\n",
      "[epoch : 64]  cost 1.067499148079326\n",
      "[epoch : 65]  cost 1.0660688000917427\n",
      "[epoch : 66]  cost 1.0648043636764808\n",
      "[epoch : 67]  cost 1.0671002014194222\n",
      "[epoch : 68]  cost 1.0653720427410946\n",
      "[epoch : 69]  cost 1.0655691033601769\n",
      "[epoch : 70]  cost 1.0634715217351915\n",
      "[epoch : 71]  cost 1.061720291290965\n",
      "[epoch : 72]  cost 1.0608693355321879\n",
      "[epoch : 73]  cost 1.0594681064571652\n",
      "[epoch : 74]  cost 1.0631009736231392\n",
      "[epoch : 75]  cost 1.061052129438945\n",
      "[epoch : 76]  cost 1.0559635938916878\n",
      "[epoch : 77]  cost 1.0593264150619517\n",
      "[epoch : 78]  cost 1.0616401697056634\n",
      "[epoch : 79]  cost 1.0542491688898619\n",
      "[epoch : 80]  cost 1.056090782369887\n",
      "[epoch : 81]  cost 1.0520849626404905\n",
      "[epoch : 82]  cost 1.051558134300367\n",
      "[epoch : 83]  cost 1.0567753340516775\n",
      "[epoch : 84]  cost 1.0541478522334775\n",
      "[epoch : 85]  cost 1.054533482960292\n",
      "[epoch : 86]  cost 1.0499782546928953\n",
      "[epoch : 87]  cost 1.0528638565540318\n",
      "[epoch : 88]  cost 1.0503895238467629\n",
      "[epoch : 89]  cost 1.048208813071252\n",
      "[epoch : 90]  cost 1.0478408160379953\n",
      "[epoch : 91]  cost 1.0492730607305256\n",
      "[epoch : 92]  cost 1.0495634807007668\n",
      "[epoch : 93]  cost 1.05016600898334\n",
      "[epoch : 94]  cost 1.0459416958263934\n",
      "[epoch : 95]  cost 1.0463492094618936\n",
      "[epoch : 96]  cost 1.0433739700487685\n",
      "[epoch : 97]  cost 1.0461735024622512\n",
      "[epoch : 98]  cost 1.0486591449805667\n",
      "[epoch : 99]  cost 1.0443041803155628\n",
      "accuracy : 0.5717999935150146\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(len(x_train) / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x = x_train[i*batch_size:(i+1)*batch_size]\n",
    "            batch_y = y_train[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            for i in range(5):\n",
    "                cost_val, _ = sess.run([cost, train], feed_dict={X:batch_x,Y:batch_y, keep_prob:0.7})\n",
    "            avg_cost += cost_val/total_batch\n",
    "        \n",
    "        print(\"[epoch : {}]  cost {}\".format(epoch, avg_cost))\n",
    "    \n",
    "    print(\"accuracy : {}\".format(sess.run(accuracy, feed_dict={X:x_train, Y:y_train, keep_prob:1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
